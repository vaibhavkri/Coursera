{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IBM Applied Data Science  Capstone","metadata":{}},{"cell_type":"markdown","source":"## Peer-graded Assignment: Capstone Project - Car accident severity (Week 1)","metadata":{}},{"cell_type":"markdown","source":"# A description of the data and how it will be used to solve the problem","metadata":{}},{"cell_type":"markdown","source":"The data set used in this project came from SDOT GIS Seattle(Data Set, Meta Data). It contains the speed, light, road condition, severity, etc. for the past road accidents. The idea is to use several supervised machine learning techniques to predict the severity given the various road conditions.\nThe data to be used in the Capstone project is the example dataset named \"Data-Collisions.csv\".\nThe dataset includes all collisions provided by SPD and recorded by Traffic Records. Collisions will display at the intersection or mid-block of a segment. The timeframe of the data is from 2004 to Present. The data is updated on a weekly basis. The metadata has been provided in the pdf.\n\nEach line in the dataset represents a single traffic accident and its various properties. The first column is the label(severity).\nThe remaining columns have different types of attributes which can be used to train the model. The model is supervised machine learning, so these observations are used to train and validate the machine learning model. The label for the data set is severity, which describes the fatality of an accident. The data has unbalanced labels, so steps should be done to balance the data, otherwise, it will create a biased machine learning model.\nIn total, there are 37 attributes/columns. Some of the attributes have missing data, so some data cleaning is required. There are both numerical and categorical types of data, such as location, number of people involved and collision types. Some or all can be used to train the model.\n\n \nFor the scope of this project, I'll look at how \"SPEEDING\", \"ROADCOND\", \"LIGHTCOND\", \"WEATHER\" parameters affect \"SEVERITYCODE\". Keep only weather in (Clear, Raining, Overcast), road condition in (Dry, Wet) and light condition in (Daylight, Dark - Street Lights On) so that the training set will not be too skewed\n \nSince this is a binary classification problem (severity code= 1 or 2), I'll use K-nearest neighbors and Logistic regression techniques. KNN is chosen because its performance on dealing with a large set of data. I also chose Logistic Regression because it provides the probability for detecting accidents. To begin with, convert the attribute labels to numerical values, and then 5000 samples from each severity label were randomly picked.\n \n\n\n<b> Logistic Regression </b>\nFor Logistic regression, the regulation coefficient was chosen to be c=0.001, which yields a Jaccard similarity score of 0.5055\n\n<b> Results </b>\nFor results, confusion matrices were plotted for both KNN and LR models.\n","metadata":{}}]}